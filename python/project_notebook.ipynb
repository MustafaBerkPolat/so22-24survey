{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be1d91a4-2903-4d4d-8a5b-dbb984c2a8ae",
   "metadata": {},
   "source": [
    "Importing libraries\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c734874-da1e-4738-8e9a-4b335a66881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import functions as f\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2f901-85e7-4b4f-9341-99fa522e4182",
   "metadata": {},
   "source": [
    "Defining folder paths for downloaded and cleaned data, as well as links for the surveys\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a6b17e-6b7e-4283-a47c-01ca7dc827b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_folder = r\"C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Stack Overflow Surveys Analysis\\raw data\"\n",
    "clean_data_folder = r\"C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Stack Overflow Surveys Analysis\\clean data\"\n",
    "\n",
    "if not os.path.exists(raw_data_folder):\n",
    "    os.makedirs(raw_data_folder)\n",
    "\n",
    "if not os.path.exists(clean_data_folder):\n",
    "    os.makedirs(clean_data_folder)\n",
    "\n",
    "survey_2022 = \"https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2022.zip\"\n",
    "survey_2023 = \"https://cdn.stackoverflow.co/files/jo7n4k8s/production/49915bfd46d0902c3564fd9a06b509d08a20488c.zip/stack-overflow-developer-survey-2023.zip\"\n",
    "survey_2024 = \"https://cdn.sanity.io/files/jo7n4k8s/production/262f04c41d99fea692e0125c342e446782233fe4.zip/stack-overflow-developer-survey-2024.zip\"\n",
    "\n",
    "links_list = [survey_2022, survey_2023, survey_2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcee3c5-f0b6-48a3-9fdc-d68ee72d45c9",
   "metadata": {},
   "source": [
    "Downloading the survey data and opening them with Pandas\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7323a4-30cd-4fa4-8b5e-3de9268759b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded from https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2022.zip under C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Stack Overflow Surveys Analysis\\raw data\\stack-overflow-developer-survey-2022.zip\n",
      "File downloaded from https://cdn.stackoverflow.co/files/jo7n4k8s/production/49915bfd46d0902c3564fd9a06b509d08a20488c.zip/stack-overflow-developer-survey-2023.zip under C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Stack Overflow Surveys Analysis\\raw data\\stack-overflow-developer-survey-2023.zip\n",
      "File downloaded from https://cdn.sanity.io/files/jo7n4k8s/production/262f04c41d99fea692e0125c342e446782233fe4.zip/stack-overflow-developer-survey-2024.zip under C:\\Users\\mpola\\OneDrive\\Desktop\\Career\\Proje\\Stack Overflow Surveys Analysis\\raw data\\stack-overflow-developer-survey-2024.zip\n"
     ]
    }
   ],
   "source": [
    "# By using rsplit, we can get the filename as it is stored in the StackOverflow servers to assign to our downloaded zips\n",
    "\n",
    "for i in links_list:\n",
    "    f.download_data(i, raw_data_folder, i.rsplit('/',1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32349c78-4128-41de-945b-48ae8b052188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all downloaded zipfile names from our download folder, in case of manual renaming inbetween steps for readability\n",
    "\n",
    "surveys = [survey for survey in os.listdir(raw_data_folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6fe7829-fc9c-4184-9e41-4f7027716109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all dataframes into a list in the order we defined the links previously, and fetching the year of the survey result\n",
    "# as a new column on the dataframe for when we merge all dataframes and split by question categories rather than year\n",
    "df_list= []\n",
    "\n",
    "for i,j in enumerate(surveys):\n",
    "    df_list.append(f.read_zip(raw_data_folder + \"\\\\\" + str(j), \"survey_results_public.csv\"))\n",
    "\n",
    "    # To get the year as a string, we iterate through the entries of our surveys list to get the digits of the strings in order.\n",
    "    # This assumes the filenames only have the year as numbers, but in this specific case there really isn't any reason for the files to\n",
    "    # have another number in their names so it works\n",
    "    year = ''\n",
    "    for k in str(j):\n",
    "        if k.isdigit():\n",
    "            year += k\n",
    "    df_list[i]['SurveyYear'] = int(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2d8fb-d44c-4635-ae2f-0a82ece396e4",
   "metadata": {},
   "source": [
    "Filtering unnecessary data and merging dataframes\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6d3882b-5171-4c33-9de4-d7ff70a257d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the intersection of all dataframe columns in our dataframe list in order to discard any column that we cannot compare year-to-year\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    if i == 0:\n",
    "        col0 = df_list[i].columns\n",
    "    else :\n",
    "        col0 = set(col0).intersection(df_list[i].columns)\n",
    "    common_cols = list(col0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f621d1-981f-4cab-ac39-deaeec7e99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non-shared columns\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i] = df_list[i][common_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37533f6f-6ef7-46e2-ad76-3ab8b8017a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging all dataframes in our list under a single master dataframe\n",
    "\n",
    "for i,j in enumerate(df_list):\n",
    "    if i == 0:\n",
    "        df_master = j\n",
    "    else :\n",
    "        df_master = pd.concat([df_master, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0484db-351c-40dc-96e2-5d378be03004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the detect_separator function to see which columns of this dataframe contain data that are checklists condensed into singular strings\n",
    "# These columns are very annoying to work with as they are, so they will be split into multiple boolean columns at a later step\n",
    "\n",
    "separator_list = f.detect_separator(df_master, 50, ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7040b9e-1d3c-4690-80e0-791a4ac2b1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# By defining a new list of shared column names, we can erase columns from this list as we go along with our column categorization \n",
    "# so we have a clean list to fall back to, as well as a one-step solution to make a \"misc\" dataframe for any columns we deemed either\n",
    "# unnecessary for our analysis or couldn't fit into a category\n",
    "\n",
    "remaining_cols = common_cols\n",
    "id_cols = ['ResponseId']\n",
    "remaining_separator_cols = [x for x in separator_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b9fde8f-7622-48d2-98a2-1d4271bc0cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WebframeHaveWorkedWith',\n",
       " 'SurveyLength',\n",
       " 'NEWSOSites',\n",
       " 'TBranch',\n",
       " 'Knowledge_3',\n",
       " 'Knowledge_5',\n",
       " 'Knowledge_6',\n",
       " 'OfficeStackAsyncWantToWorkWith',\n",
       " 'TimeAnswering',\n",
       " 'Currency',\n",
       " 'EdLevel',\n",
       " 'MiscTechHaveWorkedWith',\n",
       " 'ResponseId',\n",
       " 'WebframeWantToWorkWith',\n",
       " 'Knowledge_1',\n",
       " 'SOVisitFreq',\n",
       " 'LearnCode',\n",
       " 'SurveyYear',\n",
       " 'Employment',\n",
       " 'ToolsTechHaveWorkedWith',\n",
       " 'OfficeStackSyncWantToWorkWith',\n",
       " 'Frequency_1',\n",
       " 'ProfessionalTech',\n",
       " 'LanguageWantToWorkWith',\n",
       " 'Knowledge_4',\n",
       " 'CompTotal',\n",
       " 'SurveyEase',\n",
       " 'Knowledge_2',\n",
       " 'PlatformHaveWorkedWith',\n",
       " 'OpSysProfessional use',\n",
       " 'BuyNewTool',\n",
       " 'OpSysPersonal use',\n",
       " 'DatabaseHaveWorkedWith',\n",
       " 'ICorPM',\n",
       " 'NEWCollabToolsHaveWorkedWith',\n",
       " 'PurchaseInfluence',\n",
       " 'NEWCollabToolsWantToWorkWith',\n",
       " 'TimeSearching',\n",
       " 'SOPartFreq',\n",
       " 'SOAccount',\n",
       " 'RemoteWork',\n",
       " 'MainBranch',\n",
       " 'DevType',\n",
       " 'Age',\n",
       " 'WorkExp',\n",
       " 'YearsCode',\n",
       " 'OfficeStackAsyncHaveWorkedWith',\n",
       " 'SOComm',\n",
       " 'Frequency_3',\n",
       " 'YearsCodePro',\n",
       " 'CodingActivities',\n",
       " 'MiscTechWantToWorkWith',\n",
       " 'LearnCodeOnline',\n",
       " 'DatabaseWantToWorkWith',\n",
       " 'OrgSize',\n",
       " 'LanguageHaveWorkedWith',\n",
       " 'ToolsTechWantToWorkWith',\n",
       " 'OfficeStackSyncHaveWorkedWith',\n",
       " 'Frequency_2',\n",
       " 'Knowledge_7',\n",
       " 'ConvertedCompYearly',\n",
       " 'Country',\n",
       " 'PlatformWantToWorkWith']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51a5116a-2d83-4ffc-9652-f772bfd5a37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WebframeHaveWorkedWith',\n",
       " 'NEWSOSites',\n",
       " 'OfficeStackAsyncWantToWorkWith',\n",
       " 'MiscTechHaveWorkedWith',\n",
       " 'WebframeWantToWorkWith',\n",
       " 'LearnCode',\n",
       " 'Employment',\n",
       " 'ToolsTechHaveWorkedWith',\n",
       " 'OfficeStackSyncWantToWorkWith',\n",
       " 'ProfessionalTech',\n",
       " 'LanguageWantToWorkWith',\n",
       " 'PlatformHaveWorkedWith',\n",
       " 'OpSysProfessional use',\n",
       " 'BuyNewTool',\n",
       " 'OpSysPersonal use',\n",
       " 'DatabaseHaveWorkedWith',\n",
       " 'NEWCollabToolsHaveWorkedWith',\n",
       " 'NEWCollabToolsWantToWorkWith',\n",
       " 'DevType',\n",
       " 'OfficeStackAsyncHaveWorkedWith',\n",
       " 'CodingActivities',\n",
       " 'MiscTechWantToWorkWith',\n",
       " 'LearnCodeOnline',\n",
       " 'DatabaseWantToWorkWith',\n",
       " 'LanguageHaveWorkedWith',\n",
       " 'ToolsTechWantToWorkWith',\n",
       " 'OfficeStackSyncHaveWorkedWith',\n",
       " 'PlatformWantToWorkWith']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_separator_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aba39a9-653d-4f0c-95e9-cd9bddcc4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start off, we organize the columns about the tech respondents have worked or want to work with into their own folders, as \n",
    "# we have a lot of dataframes and letting them all sit in one folder makes it harder to work with them outside of Python\n",
    "\n",
    "HaveWorkedWith = [x for x in remaining_cols if 'HaveWorkedWith' in x]\n",
    "WantToWorkWith = [x for x in remaining_cols if 'WantToWorkWith' in x]\n",
    "\n",
    "\n",
    "if not os.path.exists(clean_data_folder + '\\\\HaveWorkedWith'):\n",
    "    os.makedirs(clean_data_folder + '\\\\HaveWorkedWith')\n",
    "\n",
    "if not os.path.exists(clean_data_folder + '\\\\WantToWorkWith'):\n",
    "    os.makedirs(clean_data_folder + '\\\\WantToWorkWith')\n",
    "\n",
    "\n",
    "for i,j in enumerate(HaveWorkedWith):\n",
    "    df_HaveWorkedWith_temp, remaining_cols = f.columns_bucket(df_master, remaining_cols, [j], id_cols)\n",
    "    if j in remaining_separator_cols:\n",
    "        remaining_separator_cols.remove(j)\n",
    "    df_HaveWorkedWith_temp.to_csv(f'{clean_data_folder}\\\\HaveWorkedWith\\\\df_' + j + '.csv', index=False)\n",
    "    \n",
    "\n",
    "for i,j in enumerate(WantToWorkWith):\n",
    "    df_WantToWorkWith_temp, remaining_cols = f.columns_bucket(df_master, remaining_cols, [j], id_cols)\n",
    "    if j in remaining_separator_cols:\n",
    "        remaining_separator_cols.remove(j)\n",
    "    df_WantToWorkWith_temp.to_csv(f'{clean_data_folder}\\\\WantToWorkWith\\\\df_' + j + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaae88e9-ac92-4649-b75d-e8efe4bbd981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we define a third folder to contain all the other dataframes that correspond to columns that contain semicolon-separated\n",
    "# strings as boolean checklists.\n",
    "\n",
    "\n",
    "bool_dfs_folder = '\\\\BooleanDataframes'\n",
    "\n",
    "if not os.path.exists(clean_data_folder + bool_dfs_folder):\n",
    "    os.makedirs(clean_data_folder + bool_dfs_folder)\n",
    "\n",
    "temp_list = []\n",
    "for i,j in enumerate(remaining_separator_cols):\n",
    "    df_temp, remaining_cols = f.columns_bucket(df_master, remaining_cols, [j], id_cols)\n",
    "    temp_list.append(j)\n",
    "    df_temp.to_csv(f'{clean_data_folder}\\\\{bool_dfs_folder}\\\\df_' + j + '.csv', index=False)\n",
    "\n",
    "remaining_separator_cols = [x for x in remaining_separator_cols if x not in temp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9e02b74-41d7-40c9-b2e4-843e1e892b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we have all the columns that are not in checklist format. These columns correlate with each other in certain ways, and\n",
    "# rather than storing each column in its own dataframe it makes sense here to do some manual work to decipher the surveys and categorize them based\n",
    "# on these correlations.\n",
    "\n",
    "# To get a better idea of which question in the survey each column corresponds to, it makes sense to get a list of unique entries of each\n",
    "# column, which we then choose an arbitrary entry from and search the survey manually, as the data given does not include the\n",
    "# information for corresponding questions outside of the survey pdf itself.\n",
    "# However, these codes are not necessary for the functionality of this project otherwise\n",
    "\n",
    "df_uniques = []\n",
    "for column in remaining_cols:\n",
    "    df_uniques.append(list(df_master[column].unique()))\n",
    "\n",
    "col_labels = [[a] + b for a,b in zip(remaining_cols, df_uniques)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eadc6c8f-1fb8-4d40-b0e0-68f48281f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicInfo = ['MainBranch', 'RemoteWork', 'Age', 'SurveyYear']\n",
    "\n",
    "\n",
    "df_BasicInfo, remaining_cols = f.columns_bucket(df_master, remaining_cols, BasicInfo, id_cols)\n",
    "df_BasicInfo.to_csv(f'{clean_data_folder}\\\\df_BasicInfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34dc9411-3f44-4bd0-958f-85b1111475cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EduWork = ['EdLevel', 'YearsCode', 'YearsCodePro', 'WorkExp', 'OrgSize', 'Country', 'Currency', 'ConvertedCompYearly']\n",
    "\n",
    "\n",
    "df_EduWork, remaining_cols = f.columns_bucket(df_master, remaining_cols, EduWork, id_cols)\n",
    "df_EduWork.to_csv(f'{clean_data_folder}\\\\df_EduWork.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bc4e0af-56de-423f-9c7a-5d4f803a36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOInfo = ['SOVisitFreq', 'SOPartFreq', 'SOComm', 'SOAccount']\n",
    "\n",
    "\n",
    "df_SOInfo, remaining_cols = f.columns_bucket(df_master, remaining_cols, SOInfo, id_cols)\n",
    "df_SOInfo.to_csv(f'{clean_data_folder}\\\\df_SOInfo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a940075-6b78-49ac-a068-c9c872cba0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProfDevSeries = [x for x in remaining_cols if 'Knowledge_' in x]\n",
    "\n",
    "for x in remaining_cols:\n",
    "     if 'Frequency_' in x:\n",
    "        ProfDevSeries.append(x)\n",
    "\n",
    "ProfDevSeries.append('TimeSearching')\n",
    "ProfDevSeries.append('TimeAnswering')\n",
    "\n",
    "\n",
    "df_ProfDevSeries, remaining_cols = f.columns_bucket(df_master, remaining_cols, ProfDevSeries, id_cols)\n",
    "df_ProfDevSeries.to_csv(f'{clean_data_folder}\\\\df_ProfDevSeries.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d8612f9-d1c7-4184-aa2f-4db942677636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Misc = df_master[remaining_cols]\n",
    "df_Misc.to_csv(f'{clean_data_folder}\\\\df_Misc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b364f-2860-41bb-95bd-95b462d8109d",
   "metadata": {},
   "source": [
    "Data Cleaning and Optimization\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a38610c9-1941-4e1f-8e9f-cee3eeabcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point we have a lot of csv files that have plenty of columns with NaN values, as well as csv files containing dataframes that\n",
    "# all have only boolean columns outside of the ResponseId columns. The first problem is easy to solve using dropna with no issues,\n",
    "# but the second problem has multiple situational fixes that may or may not be preferred based on the dataframe we apply the fix to\n",
    "\n",
    "# The first step is to dropna the normal dataframes with mixed column types.\n",
    "\n",
    "files_list = os.listdir(clean_data_folder)\n",
    "files_list_df = [item for item in files_list if item.startswith('df_')]\n",
    "\n",
    "for csv in files_list_df:\n",
    "    df_temp = pd.read_csv(f'{clean_data_folder}\\\\{csv}')\n",
    "    df_temp['ResponseId'] = np.arange(df_temp.shape[0]).astype(int)\n",
    "    df_temp.dropna(axis=0, thresh=2, inplace=True)\n",
    "    \n",
    "    for column in separator_list:\n",
    "        # This for loop would be useful, if not for our categorization of dataframes into folders. It is still left here\n",
    "        # on the off-chance we made an oversight or go back to a \"all files in one folder\" format later on\n",
    "        if column in df_temp:\n",
    "            df_temp = f.split_string_checklist(df_temp, column, ';')\n",
    "    df_temp.to_csv(f'{clean_data_folder}\\\\{csv}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6fe9b9c-6413-4af2-815f-61e7c15a16f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When it comes to the dataframes that store checklist answer (ie. select all that apply)\n",
    "# data as strings with semicolon separators, we split these into\n",
    "# a multitude of boolean columns. This splitting makes the data easier to work with, but can increase filesizes depending on\n",
    "# how many different possible entires there were on the checklist\n",
    "\n",
    "files_list = os.listdir(clean_data_folder)\n",
    "folders_list = [item for item in files_list if not item.startswith('df_')]\n",
    "\n",
    "for folder in folders_list:\n",
    "    files_list2 = os.listdir(clean_data_folder + '\\\\' + folder)\n",
    "    files_list2_df = [item for item in files_list2 if item.startswith('df_')]\n",
    "    \n",
    "    for csv_name in files_list2_df:\n",
    "        df_temp = pd.read_csv(f'{clean_data_folder}\\\\{folder}\\\\{csv_name}')\n",
    "        \n",
    "        df_temp['ResponseId'] = np.arange(df_temp.shape[0]).astype(int)\n",
    "        df_temp.dropna(axis=0, thresh=2, inplace=True)\n",
    "        \n",
    "        for column in separator_list:\n",
    "            if column in df_temp:\n",
    "                df_temp = f.split_string_checklist(df_temp, column, ';')\n",
    "\n",
    "        df_temp.to_csv(f'{clean_data_folder}\\\\{folder}\\\\{csv_name}', index=False)\n",
    "\n",
    "        col_name = csv_name.lstrip('df_').rstrip('.csv')\n",
    "        df_temp = f.table_stack(df_temp, id_cols[0], col_name)\n",
    "\n",
    "        # In some cases, these boolean checklist dataframes can have a majority of rows where only one column is set to True, with\n",
    "        # dozens set to false. In such cases, we end up with nearly 230k rows and dozens of columns that convey data that could just\n",
    "        # as easily be represented with more rows, but only two columns: one to list ResponseId (which will no longer be unique\n",
    "        # per row) and one to list the occurences of answers as strings.\n",
    "\n",
    "        # If working strictly inside Python, we could use a dictionary to store the different possible answers, and have our\n",
    "        # second column list only a numeric identifier that correspond to the answer, but such a simplification\n",
    "        # makes the data harder to configure in external programs to work with.\n",
    "\n",
    "        # As this simplification does not necessarily make the dataframes faster or easier to work with, we store these in a \n",
    "        # separate folder with separate .csv files so that we can pick and choose which variant we use depending\n",
    "        # on whichever one is more convenient for the program we use them with\n",
    "        if not os.path.exists(f'{clean_data_folder}\\\\{folder}\\\\stacked'):\n",
    "            os.makedirs(f'{clean_data_folder}\\\\{folder}\\\\stacked')\n",
    "        \n",
    "        df_temp.to_csv(f'{clean_data_folder}\\\\{folder}\\\\stacked\\\\{csv_name}', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a94251b-22ec-4502-a13e-a801488692ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>YearsCode</th>\n",
       "      <th>YearsCodePro</th>\n",
       "      <th>WorkExp</th>\n",
       "      <th>OrgSize</th>\n",
       "      <th>Country</th>\n",
       "      <th>Currency</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>ResponseId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>CAD\\tCanadian dollar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
       "      <td>GBP\\tPound sterling</td>\n",
       "      <td>40205.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100 to 499 employees</td>\n",
       "      <td>Israel</td>\n",
       "      <td>ILS\\tIsraeli new shekel</td>\n",
       "      <td>215232.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>USD\\tUnited States dollar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220523</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,000 to 4,999 employees</td>\n",
       "      <td>India</td>\n",
       "      <td>INR\\tIndian rupee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220524</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>38</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>EUR European Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220525</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 to 9 employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220526</th>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,000 to 4,999 employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220527</th>\n",
       "      <td>Secondary school (e.g. American high school, G...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>Germany</td>\n",
       "      <td>EUR European Euro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220528 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  EdLevel YearsCode  \\\n",
       "0                                                     NaN       NaN   \n",
       "1         Master’s degree (M.A., M.S., M.Eng., MBA, etc.)        14   \n",
       "2            Bachelor’s degree (B.A., B.S., B.Eng., etc.)        20   \n",
       "3            Bachelor’s degree (B.A., B.S., B.Eng., etc.)         8   \n",
       "4         Master’s degree (M.A., M.S., M.Eng., MBA, etc.)        15   \n",
       "...                                                   ...       ...   \n",
       "220523       Bachelor’s degree (B.A., B.S., B.Eng., etc.)         4   \n",
       "220524       Bachelor’s degree (B.A., B.S., B.Eng., etc.)        38   \n",
       "220525       Bachelor’s degree (B.A., B.S., B.Eng., etc.)         5   \n",
       "220526       Bachelor’s degree (B.A., B.S., B.Eng., etc.)         9   \n",
       "220527  Secondary school (e.g. American high school, G...         5   \n",
       "\n",
       "       YearsCodePro  WorkExp                   OrgSize  \\\n",
       "0               NaN      NaN                       NaN   \n",
       "1                 5      NaN        20 to 99 employees   \n",
       "2                17      NaN      100 to 499 employees   \n",
       "3                 3      NaN        20 to 99 employees   \n",
       "4               NaN      NaN                       NaN   \n",
       "...             ...      ...                       ...   \n",
       "220523            7      NaN  1,000 to 4,999 employees   \n",
       "220524           24      NaN        20 to 99 employees   \n",
       "220525            3      NaN          2 to 9 employees   \n",
       "220526            5      NaN  1,000 to 4,999 employees   \n",
       "220527            2      5.0        20 to 99 employees   \n",
       "\n",
       "                                                  Country  \\\n",
       "0                                                  Canada   \n",
       "1       United Kingdom of Great Britain and Northern I...   \n",
       "2                                                  Israel   \n",
       "3                                United States of America   \n",
       "4                                                 Germany   \n",
       "...                                                   ...   \n",
       "220523                                              India   \n",
       "220524                                            Belgium   \n",
       "220525                                                NaN   \n",
       "220526                                                NaN   \n",
       "220527                                            Germany   \n",
       "\n",
       "                         Currency  ConvertedCompYearly  ResponseId  \n",
       "0            CAD\\tCanadian dollar                  NaN           1  \n",
       "1             GBP\\tPound sterling              40205.0           2  \n",
       "2         ILS\\tIsraeli new shekel             215232.0           3  \n",
       "3       USD\\tUnited States dollar                  NaN           4  \n",
       "4                             NaN                  NaN           5  \n",
       "...                           ...                  ...         ...  \n",
       "220523          INR\\tIndian rupee                  NaN      227880  \n",
       "220524          EUR European Euro                  NaN      227883  \n",
       "220525                        NaN                  NaN      227884  \n",
       "220526                        NaN                  NaN      227886  \n",
       "220527          EUR European Euro                  NaN      227887  \n",
       "\n",
       "[220528 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = pd.read_csv(f'{clean_data_folder}\\\\df_EduWork.csv')\n",
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff5975d-8a38-4531-92e6-b2dbc6863776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
